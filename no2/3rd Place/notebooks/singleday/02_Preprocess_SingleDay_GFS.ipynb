{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57b79187",
   "metadata": {},
   "source": [
    "<h1><center> NASA Airathon - NO2 Track </center></h1>\n",
    "\n",
    "### <center> Single day: extract GFS data for a specific location </center>\n",
    "\n",
    "<div style=\"text-align: center\"> \n",
    "    Dr. Sukanta Basu <br/> Associate Professor <br/> Delft University of Technology, The Netherlands <br/> Email: s.basu@tudelft.nl<br/> https://sites.google.com/view/sukantabasu/\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fc1e43",
   "metadata": {},
   "source": [
    "#### Log\n",
    "\n",
    "Last updated: 4th April, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc5e6f5",
   "metadata": {},
   "source": [
    "#### User instructions \n",
    "\n",
    "1. Provide the latitude (LATx) and longitude (LONx) of the location of interest \n",
    "\n",
    "2. Provide the directory name containing GFS data for a specific date. \n",
    "\n",
    "3. This notebook will extract GFS data for the location of interest and save it in testGFS.csv file inside data/singleday/processed/test/GFS/ directory. \n",
    "\n",
    "As an illustrative example, we use the centroid of the ZZ8JF grid (longitude: -117.3274620089189, latitude: 33.664840117597805). This information is available from the data/airathon/processed/grid_latlon.csv file. \n",
    "\n",
    "Also, we select August 24, 2021 as our case study date. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec1c621",
   "metadata": {},
   "source": [
    "#### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddde0791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import netCDF4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8768af8f",
   "metadata": {},
   "source": [
    "#### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f38bebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR    = '../../'\n",
    "\n",
    "#Only one day data is included in the repo_sukantabasu\n",
    "GFS_DIR     = ROOT_DIR + 'data/singleday/raw/GFS/'\n",
    "\n",
    "#Location of processed datasets\n",
    "EXTDATA_DIR = ROOT_DIR + 'data/singleday/processed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad612b1",
   "metadata": {},
   "source": [
    "#### Provide coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a536e5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATx = 33.664840117597805\n",
    "LONx = -117.3274620089189"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f1c16d",
   "metadata": {},
   "source": [
    "#### Provide date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdb5eb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "YR = 2021\n",
    "MO = 8\n",
    "DY = 24\n",
    "HR = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c570b16b",
   "metadata": {},
   "source": [
    "#### Compute Julian day and week day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "580d76d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'year': [YR],\n",
    "                   'month': [MO],\n",
    "                   'day': [DY]})\n",
    "JD = (pd.to_datetime(df)).dt.dayofyear\n",
    "WD = (pd.to_datetime(df)).dt.weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacba7c9",
   "metadata": {},
   "source": [
    "#### Compute nearest grid point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef31a788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearestGridFAST(LAT,LON,LATx,LONx):\n",
    "    \n",
    "    dLAT = np.abs(LAT - LATx)\n",
    "    dLON = np.abs(LON - LONx)\n",
    "    \n",
    "    dTOT = dLAT + dLON #taxi-cab distance\n",
    "    \n",
    "    #Interesting function; https://stackoverflow.com/questions/3230067/numpy-minimum-in-row-column-format\n",
    "    r_min, c_min = np.unravel_index(dTOT.argmin(), dTOT.shape)\n",
    "    \n",
    "    return r_min, c_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e32ff3d",
   "metadata": {},
   "source": [
    "#### Calculate required forecast horizon based on location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91932abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAX/\n"
     ]
    }
   ],
   "source": [
    "if (LONx > 120) & (LONx < 122):\n",
    "    strCITY = 'TAI/'\n",
    "    fcstHRini = 15\n",
    "    fcstHRfin = 39+1\n",
    "elif (LONx > 76) & (LONx < 78):\n",
    "    strCITY = 'DEL/'\n",
    "    fcstHRini = 18\n",
    "    fcstHRfin = 42+1\n",
    "elif (LONx > -119) & (LONx < -116):\n",
    "    strCITY = 'LAX/'\n",
    "    fcstHRini = 6\n",
    "    fcstHRfin = 30+1        \n",
    "else:\n",
    "    strCITY = 'XXX/'\n",
    "\n",
    "print(strCITY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9eed05",
   "metadata": {},
   "source": [
    "#### Extract GFS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b841e594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.06158953e+01  7.83058817e-01  6.47857207e-01 -8.23150893e-02\n",
      "   9.84193997e-01 -1.77093693e-01  2.91373206e+01  1.77946777e+01\n",
      "   0.00000000e+00  8.03000031e+01  2.89831482e+02  2.58959961e+00\n",
      "   1.41667065e+02  1.06545696e+01  4.91800276e-01  6.22303298e-01\n",
      "   1.02213335e-01  5.88641393e-01  8.08394279e-01  2.03624673e+00\n",
      "  -2.00932622e+00  0.00000000e+00  8.40000000e+01  2.88092865e+02\n",
      "   3.43923950e+00  2.01939503e+02  1.06647186e+01  4.39861571e-01\n",
      "   6.60091954e-01  1.76288418e-01  8.03931885e-01  5.94721384e-01\n",
      "   1.65030006e+01 -1.54204106e+00  0.00000000e+00  8.38000031e+01\n",
      "   2.87260101e+02  4.19110107e+00  8.64119219e+01  1.44277786e+02\n",
      "   5.68845488e-01  5.49083747e-01 -1.53557289e-02  7.88129369e-01\n",
      "   6.15509624e-01  1.02825732e+01  8.96738243e+00  0.00000000e+00\n",
      "   5.77000008e+01  2.93494659e+02 -1.16729736e+00 -2.98903572e+03\n",
      "   9.85858521e+02  1.63897369e+00  1.92926067e+00  7.08189271e-02\n",
      "  -1.08523463e-01 -9.94093888e-01  4.30833306e+00  1.14826683e+02\n",
      "   2.00000000e+03  1.96000004e+01  3.02898224e+02 -2.19979858e+00\n",
      "  -2.61052481e+01  1.87449927e+03  3.00142629e+00  3.16561019e+00\n",
      "   2.31297533e-02 -4.76344088e-01 -8.79258955e-01  1.19469571e+00\n",
      "   4.12921631e+02  5.00000000e+03  1.30000000e+01  3.07584167e+02\n",
      "  -2.84942627e+00 -1.05705181e+02  1.38321204e+03  2.20435302e+00\n",
      "   2.29181889e+00  1.68991477e-02 -3.85583004e-01 -9.22673153e-01\n",
      "   3.82735114e+00  3.60066071e+02  2.40000000e+03  1.62000008e+01\n",
      "   3.05985779e+02 -2.02676392e+00 -2.64926830e+02  1.27098064e+01\n",
      "   1.49234680e+00  1.72763661e+00  6.35826398e-02  4.06908851e-01\n",
      "  -9.13468766e-01  3.59527498e-01  2.91085320e+01  0.00000000e+00\n",
      "   4.50000000e+01  2.94799988e+02  2.77920532e+00  5.02012342e+01\n",
      "   1.07631931e+01  3.00747821e-01  4.76465302e-01  1.99828790e-01\n",
      "   6.86846019e-01  7.26802963e-01  2.84375916e+01  1.26567135e+01\n",
      "   0.00000000e+00  5.42999992e+01  2.91958618e+02  4.04776001e+00\n",
      "   1.31094604e+02]]\n"
     ]
    }
   ],
   "source": [
    "GFSdata = np.zeros((1,13*9)) #13 variables (PBLH, M10, M100, alpha, sinX100, cosX100, \n",
    "                                    #beta, SHFX, VENT, RH, T2, T100-T2, Rig); \n",
    "                                    #24 h = 9 x 3-hourly samples spanning 0 h to 0 h\n",
    "\n",
    "cnt = 0\n",
    "for fcstHR in np.arange(fcstHRini,fcstHRfin,3): #I use data from 3 UTC to 24 UTC\n",
    "\n",
    "    strFILE = 'gfs.0p25.' + str(YR) + str(MO).zfill(2) + str(DY).zfill(2) + str(HR).zfill(2) + '.f' + str(fcstHR).zfill(3) + '.grib2.nc'\n",
    "\n",
    "    #-----------------\n",
    "    #TMP, U GRD, V GRD, RH are stored here\n",
    "    fileGFS_VAR1 = Path(GFS_DIR + 'VAR1/' + strFILE)\n",
    "    dataGFS_VAR1 = netCDF4.Dataset(fileGFS_VAR1,'r')\n",
    "\n",
    "    #PBLH, SHFX, VRATE are stored here\n",
    "    fileGFS_VAR2 = Path(GFS_DIR + 'VAR2/' + strFILE)\n",
    "    dataGFS_VAR2 = netCDF4.Dataset(fileGFS_VAR2,'r')\n",
    "    #-----------------\n",
    "\n",
    "    #-----------------\n",
    "    LAT  = dataGFS_VAR1.variables['lat'][:]\n",
    "    LON  = dataGFS_VAR1.variables['lon'][:]\n",
    "    if (strCITY == 'LAX/'): \n",
    "        LON = LON - 360 #GFS outputs data as 240 E instead of -120 W\n",
    "    LON2d, LAT2d = np.meshgrid(LON,LAT)\n",
    "\n",
    "    r_min, c_min = nearestGridFAST(LAT2d,LON2d,LATx,LONx)\n",
    "    #-----------------\n",
    "\n",
    "    #PBL height\n",
    "    PBLH = np.squeeze(dataGFS_VAR2.variables['HPBL_L1'][:])\n",
    "    PBLHi = PBLH[r_min][c_min]\n",
    "    GFSdata[0,cnt] = PBLHi\n",
    "    cnt = cnt + 1\n",
    "    \n",
    "    #U component of velocity\n",
    "    dum  = np.squeeze(dataGFS_VAR1.variables['U_GRD_L103'][:])\n",
    "    U100 = np.squeeze(dum[0,:,:])\n",
    "    U10  = np.squeeze(dum[1,:,:])\n",
    "    U10i = U10[r_min][c_min]\n",
    "    U100i= U100[r_min][c_min]\n",
    "    \n",
    "    #V component of velocity\n",
    "    dum  = np.squeeze(dataGFS_VAR1.variables['V_GRD_L103'][:])\n",
    "    V100 = np.squeeze(dum[0,:,:])\n",
    "    V10  = np.squeeze(dum[1,:,:])\n",
    "    V10i = V10[r_min][c_min]\n",
    "    V100i= V100[r_min][c_min]\n",
    "    \n",
    "    #Wind speed and direction\n",
    "    M10i      = np.sqrt(U10i**2  + V10i**2)\n",
    "    M100i     = np.sqrt(U100i**2 + V100i**2)\n",
    "    alpha     = np.log(M100i/M10i)/np.log(10)\n",
    "\n",
    "    RtoD      = 180/np.pi\n",
    "    X10i      = np.arctan2(-U10i,-V10i)*RtoD\n",
    "    if X10i < 0:\n",
    "        X10i = X10i + 360\n",
    "    X100i     = np.arctan2(-U100i,-V100i)*RtoD\n",
    "    if X100i < 0:\n",
    "        X100i = X100i + 360\n",
    "    sinX100i  = np.sin(X100i/RtoD)\n",
    "    cosX100i  = np.cos(X100i/RtoD)\n",
    "    beta      = np.abs(X100i-X10i)\n",
    "    if beta > 180:\n",
    "        beta = 360 - beta\n",
    "\n",
    "    GFSdata[0,cnt] = M10i\n",
    "    cnt = cnt + 1\n",
    "\n",
    "    GFSdata[0,cnt] = M100i\n",
    "    cnt = cnt + 1\n",
    "\n",
    "    GFSdata[0,cnt] = alpha \n",
    "    cnt = cnt + 1\n",
    "\n",
    "    GFSdata[0,cnt] = sinX100i \n",
    "    cnt = cnt + 1\n",
    "\n",
    "    GFSdata[0,cnt] = cosX100i \n",
    "    cnt = cnt + 1\n",
    "\n",
    "    GFSdata[0,cnt] = beta \n",
    "    cnt = cnt + 1\n",
    "    \n",
    "    #Sensible heat flux\n",
    "    SHFX  = np.squeeze(dataGFS_VAR2.variables['SHTFL_L1_Avg_1'][:])\n",
    "    SHFXi = SHFX[r_min][c_min]\n",
    "    GFSdata[0,cnt] = SHFXi\n",
    "    cnt = cnt + 1\n",
    "    \n",
    "    #Ventillation rate\n",
    "    VENT = np.squeeze(dataGFS_VAR2.variables['VRATE_L220'][:])\n",
    "    VENTi = VENT[r_min][c_min]\n",
    "    GFSdata[0,cnt] = VENTi\n",
    "    cnt = cnt + 1    \n",
    "    \n",
    "    #Relative humidity\n",
    "    RH   = np.squeeze(dataGFS_VAR1.variables['R_H_L103'][:])\n",
    "    RHi   = RH[r_min][c_min]\n",
    "    GFSdata[0,cnt] = RHi\n",
    "    cnt = cnt + 1\n",
    "\n",
    "    #Air temperature \n",
    "    dum  = np.squeeze(dataGFS_VAR1.variables['TMP_L103'][:])\n",
    "    T100 = np.squeeze(dum[0,:,:])\n",
    "    T2   = np.squeeze(dum[1,:,:])\n",
    "    T100i= T100[r_min][c_min]\n",
    "    T2i  = T2[r_min][c_min]\n",
    "    GFSdata[0,cnt] = T2i\n",
    "    cnt = cnt + 1\n",
    "    \n",
    "    dT   = T100 - T2\n",
    "    dTi   = dT[r_min][c_min]\n",
    "    GFSdata[0,cnt] = dTi\n",
    "    cnt = cnt + 1\n",
    "    \n",
    "    #Gradient Richardson Number\n",
    "    GFSdata[0,cnt] = (T100i - T2i)/(M100i - M10i)**2\n",
    "    cnt = cnt + 1                \n",
    "\n",
    "    #-----------------\n",
    "\n",
    "print(GFSdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cff3c4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Save GFS data in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "759839c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   WDAY   sinJDAY   cosJDAY     PBLH_0     M10_0    M100_0   alpha_0  \\\n",
      "0     1 -0.796183 -0.605056  10.615895  0.783059  0.647857 -0.082315   \n",
      "\n",
      "   sinX100_0  cosX100_0     beta_0  ...  alpha_24  sinX100_24  cosX100_24  \\\n",
      "0   0.984194  -0.177094  29.137321  ...  0.199829    0.686846    0.726803   \n",
      "\n",
      "     beta_24    SHFX_24  VENT_24      RH_24       T2_24    dT_24      Rig_24  \n",
      "0  28.437592  12.656713      0.0  54.299999  291.958618  4.04776  131.094604  \n",
      "\n",
      "[1 rows x 120 columns]\n"
     ]
    }
   ],
   "source": [
    "df_new = pd.DataFrame(data=GFSdata)\n",
    "df_new.columns = ['PBLH_0' ,'M10_0' ,'M100_0' ,'alpha_0', 'sinX100_0', 'cosX100_0', \n",
    "                  'beta_0', 'SHFX_0', 'VENT_0', 'RH_0', 'T2_0', 'dT_0', 'Rig_0',\n",
    "                  'PBLH_3' ,'M10_3' ,'M100_3' ,'alpha_3', 'sinX100_3', 'cosX100_3', \n",
    "                  'beta_3', 'SHFX_3', 'VENT_3', 'RH_3', 'T2_3', 'dT_3', 'Rig_3',\n",
    "                  'PBLH_6' ,'M10_6' ,'M100_6' ,'alpha_6', 'sinX100_6', 'cosX100_6', \n",
    "                  'beta_6', 'SHFX_6', 'VENT_6', 'RH_6', 'T2_6', 'dT_6', 'Rig_6',\n",
    "                  'PBLH_9' ,'M10_9' ,'M100_9' ,'alpha_9', 'sinX100_9', 'cosX100_9', \n",
    "                  'beta_9', 'SHFX_9', 'VENT_9', 'RH_9', 'T2_9', 'dT_9', 'Rig_9',\n",
    "                  'PBLH_12','M10_12','M100_12','alpha_12','sinX100_12','cosX100_12',\n",
    "                  'beta_12','SHFX_12','VENT_12','RH_12','T2_12','dT_12','Rig_12',\n",
    "                  'PBLH_15','M10_15','M100_15','alpha_15','sinX100_15','cosX100_15',\n",
    "                  'beta_15','SHFX_15','VENT_15','RH_15','T2_15','dT_15','Rig_15',\n",
    "                  'PBLH_18','M10_18','M100_18','alpha_18','sinX100_18','cosX100_18',\n",
    "                  'beta_18','SHFX_18','VENT_18','RH_18','T2_18','dT_18', 'Rig_18',\n",
    "                  'PBLH_21','M10_21','M100_21','alpha_21','sinX100_21','cosX100_21',\n",
    "                  'beta_21','SHFX_21','VENT_21','RH_21','T2_21','dT_21', 'Rig_21',\n",
    "                  'PBLH_24','M10_24','M100_24','alpha_24','sinX100_24','cosX100_24',\n",
    "                  'beta_24','SHFX_24','VENT_24','RH_24','T2_24','dT_24', 'Rig_24']       \n",
    "    \n",
    "df_new.insert(0, 'WDAY', WD)\n",
    "df_new.insert(1, 'sinJDAY', np.sin(2*np.pi*JD/365))\n",
    "df_new.insert(2, 'cosJDAY', np.cos(2*np.pi*JD/365))\n",
    "\n",
    "print(df_new)\n",
    "\n",
    "df_new.to_csv(EXTDATA_DIR + 'test/GFS/' + 'testGFS.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
