{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eb20750-b21a-4899-97e2-18daac714a02",
   "metadata": {},
   "source": [
    "## Processing train maiac data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f5f9d6-1ac4-4d6c-868f-7f4b568a9730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import datetime\n",
    "import gc\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "import rioxarray as rxr\n",
    "from rioxarray.exceptions import NoDataInBounds\n",
    "from tqdm import tqdm\n",
    "import xarray\n",
    "\n",
    "\n",
    "gc.enable()\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "DATA_DIR = '../data/raw/data'\n",
    "PRODUCT = 'maiac'\n",
    "SPLIT = 'train'\n",
    "LOCATION_MAP = {'Taipei': 'tpe', 'Delhi': 'dl', 'Los Angeles (SoCAB)': 'la'}\n",
    "\n",
    "train_data = pd.read_csv('../data/train_labels.csv')\n",
    "satellite_data = pd.read_csv('../data/pm25_satellite_metadata.csv')\n",
    "satellite_data = satellite_data[satellite_data['split'] == SPLIT]\n",
    "satellite_data = satellite_data[satellite_data['product'] == PRODUCT]\n",
    "grid_data = pd.read_csv('../data/grid_metadata.csv')\n",
    "\n",
    "REQUIRED_BANDS_0 = ['Optical_Depth_047', 'Optical_Depth_055', 'AOD_Uncertainty', 'FineModeFraction', 'Column_WV', 'AOD_QA', 'AOD_MODEL', 'Injection_Height']\n",
    "SAVE_DIR = \"../data/raw/proc_data\"\n",
    "\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)\n",
    "indices = [idx for idx in range(len(train_data))]\n",
    "print(\"Processing %d instances...\" %len(indices))\n",
    "\n",
    "\n",
    "def project_and_save(cur_satdata, el, geometry, idx):\n",
    "    dt = datetime.datetime.strptime(el['datetime'], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    cur_satdata['time_end'] = cur_satdata['time_end'].apply(lambda x:datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S+00:00'))\n",
    "    possible = cur_satdata[cur_satdata['time_end'] < dt].sort_values('time_end', ascending=False).reset_index()\n",
    "    if len(possible) == 0:\n",
    "        assets = {}\n",
    "        for band in REQUIRED_BANDS_0:\n",
    "            assets[band] = np.nan\n",
    "        assets['label'] = np.nan\n",
    "        np.savez_compressed(os.path.join(SAVE_DIR, f\"{idx}.npz\"), **assets)\n",
    "        return\n",
    "    # assert len(possible) == 1, f\"{len(possible)} possible files found for {pdt}\"\n",
    "    assets = {}\n",
    "    for k in range(len(possible)):\n",
    "        filename = possible['granule_id'].iloc[k]\n",
    "        filename = os.path.join(DATA_DIR, SPLIT, PRODUCT, filename[:4], filename)\n",
    "\n",
    "        data = rxr.open_rasterio(filename, masked=True)\n",
    "        geometries = [\n",
    "            {\n",
    "                'type': 'Polygon',\n",
    "                'coordinates': [geometry]\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "        try:\n",
    "            clipped_0 = data[0].rio.clip(geometries, crs=4326)\n",
    "        except NoDataInBounds:\n",
    "            continue\n",
    "        assets['filename'] = filename\n",
    "        break\n",
    "    else:\n",
    "        print(f\"No data for {dt}, index: {idx}\")\n",
    "        \n",
    "    for band in REQUIRED_BANDS_0:\n",
    "        band_data = np.array(clipped_0[band].as_numpy())\n",
    "        assets[band] = band_data\n",
    "\n",
    "    assets['label'] = el['value']\n",
    "    np.savez_compressed(os.path.join(SAVE_DIR, f\"{idx}.npz\"), **assets)\n",
    "\n",
    "\n",
    "for idx in tqdm(indices):\n",
    "    el = train_data.iloc[idx]\n",
    "    grid_id = el['grid_id']\n",
    "    location = grid_data[grid_data['grid_id'] == grid_id]['location'].values[0]\n",
    "    cur_satdata = satellite_data[satellite_data['location'] == LOCATION_MAP[location]]\n",
    "\n",
    "    geometry = grid_data[grid_data['grid_id'] == grid_id]['wkt'].values[0]\n",
    "    geometry = geometry.replace('(', '', -1)\n",
    "    geometry = geometry.replace(')', '', -1)\n",
    "    geometry = geometry.replace(',', '', -1)\n",
    "    geometry = list(map(float, geometry.split()[1:]))\n",
    "    geometry = [geometry[i:i+2] for i in range(0, len(geometry), 2)]\n",
    "\n",
    "    project_and_save(cur_satdata, el, geometry, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55cba2c-5f1e-46b0-87bc-0eddce1a4c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_features(path_dir: str, total: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load features from .npz files.\n",
    "    \"\"\"\n",
    "    features = defaultdict(lambda:[])\n",
    "    for idx in tqdm(range(total)):\n",
    "        filename = os.path.join(path_dir, f\"{idx}.npz\")\n",
    "        if not os.path.exists(filename):\n",
    "            continue\n",
    "        data = np.load(filename)\n",
    "        for key in data.keys():\n",
    "            if key in ['filename', 'label']:\n",
    "                continue\n",
    "            _band = data[key].ravel()\n",
    "            _band = np.concatenate((\n",
    "                _band[_band >= 0], _band[_band < 0]\n",
    "            )) # removing nan values\n",
    "            mean, var = _band.mean(), _band.std() ** 2\n",
    "            features[key + '_mean'].append(mean)\n",
    "            features[key + '_var'].append(var)\n",
    "    k = len(features[list(features.keys())[0]])\n",
    "    for _ in range(total - k):\n",
    "        for k in features.keys():\n",
    "            features[k].append(np.nan)\n",
    "    return pd.DataFrame(features)\n",
    "\n",
    "\n",
    "train_maiac = _load_features(SAVE_DIR, len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450c32da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace data with data before midnight of current day if it exists\n",
    "features = train_maiac.columns.tolist()\n",
    "train_maiac['datetime'] = train_maiac['datetime'].apply(\n",
    "    lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    ")\n",
    "train_maiac['grid_id'] = train_data['grid_id']\n",
    "\n",
    "new_data = defaultdict(lambda: [])\n",
    "for idx in tqdm(range(train_maiac.shape[0])):\n",
    "    el = train_maiac.iloc[idx]\n",
    "    dt = el['datetime']\n",
    "    cur_data = train_maiac[train_maiac['grid_id'] == el['grid_id']]\n",
    "    cur_data = cur_data[cur_data['datetime'] > dt].sort_values('datetime', ascending=True).reset_index()\n",
    "    if len(cur_data) == 0 or cur_data.iloc[0]['datetime'] - dt > datetime.timedelta(1, 0):\n",
    "        for k in features:\n",
    "            new_data[k].append(train_maiac.iloc[idx][k])\n",
    "        continue\n",
    "    for k in features:\n",
    "        new_data[k].append(cur_data.iloc[0][k])\n",
    "\n",
    "train_maiac = pd.DataFrame(new_data)\n",
    "train_maiac.to_csv('../data/proc/train_maiac.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc08989d-9bdc-4108-8db3-37ae4aba39de",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Processing test maiac data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d4e009-8f89-4133-8fff-be7ca4966b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import datetime\n",
    "import gc\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "import rioxarray as rxr\n",
    "from rioxarray.exceptions import NoDataInBounds\n",
    "from tqdm import tqdm\n",
    "import xarray\n",
    "\n",
    "\n",
    "gc.enable()\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "DATA_DIR = '../data/raw/data'\n",
    "PRODUCT = 'maiac'\n",
    "SPLIT = 'test'\n",
    "LOCATION_MAP = {'Taipei': 'tpe', 'Delhi': 'dl', 'Los Angeles (SoCAB)': 'la'}\n",
    "\n",
    "train_data = pd.read_csv('../data/submission_format.csv')\n",
    "satellite_data = pd.read_csv('../data/pm25_satellite_metadata.csv')\n",
    "satellite_data = satellite_data[satellite_data['split'] == SPLIT]\n",
    "satellite_data = satellite_data[satellite_data['product'] == PRODUCT]\n",
    "grid_data = pd.read_csv('../data/grid_metadata.csv')\n",
    "\n",
    "REQUIRED_BANDS_0 = ['Optical_Depth_047', 'Optical_Depth_055', 'AOD_Uncertainty', 'FineModeFraction', 'Column_WV', 'AOD_QA', 'AOD_MODEL', 'Injection_Height']\n",
    "SAVE_DIR = \"../data/raw/proc_data_test\"\n",
    "\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)\n",
    "indices = [idx for idx in range(len(train_data))]\n",
    "print(\"Processing %d instances...\" %len(indices))\n",
    "\n",
    "\n",
    "def project_and_save(cur_satdata, el, geometry, idx):\n",
    "    dt = datetime.datetime.strptime(el['datetime'], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    cur_satdata['time_end'] = cur_satdata['time_end'].apply(lambda x:datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S+00:00'))\n",
    "    possible = cur_satdata[cur_satdata['time_end'] < dt].sort_values('time_end', ascending=False).reset_index()\n",
    "    if len(possible) == 0:\n",
    "        assets = {}\n",
    "        for band in REQUIRED_BANDS_0:\n",
    "            assets[band] = np.nan\n",
    "        assets['label'] = np.nan\n",
    "        np.savez_compressed(os.path.join(SAVE_DIR, f\"{idx}.npz\"), **assets)\n",
    "        return\n",
    "    # assert len(possible) == 1, f\"{len(possible)} possible files found for {pdt}\"\n",
    "    assets = {}\n",
    "    for k in range(len(possible)):\n",
    "        filename = possible['granule_id'].iloc[k]\n",
    "        filename = os.path.join(DATA_DIR, SPLIT, PRODUCT, filename[:4], filename)\n",
    "\n",
    "        data = rxr.open_rasterio(filename, masked=True)\n",
    "        geometries = [\n",
    "            {\n",
    "                'type': 'Polygon',\n",
    "                'coordinates': [geometry]\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "        try:\n",
    "            clipped_0 = data[0].rio.clip(geometries, crs=4326)\n",
    "        except NoDataInBounds:\n",
    "            continue\n",
    "        assets['filename'] = filename\n",
    "        break\n",
    "    else:\n",
    "        print(f\"No data for {dt}, index: {idx}\")\n",
    "        \n",
    "    for band in REQUIRED_BANDS_0:\n",
    "        band_data = np.array(clipped_0[band].as_numpy())\n",
    "        assets[band] = band_data\n",
    "\n",
    "    assets['label'] = el['value']\n",
    "    np.savez_compressed(os.path.join(SAVE_DIR, f\"{idx}.npz\"), **assets)\n",
    "\n",
    "\n",
    "for idx in tqdm(indices):\n",
    "    el = train_data.iloc[idx]\n",
    "    grid_id = el['grid_id']\n",
    "    location = grid_data[grid_data['grid_id'] == grid_id]['location'].values[0]\n",
    "    cur_satdata = satellite_data[satellite_data['location'] == LOCATION_MAP[location]]\n",
    "\n",
    "    geometry = grid_data[grid_data['grid_id'] == grid_id]['wkt'].values[0]\n",
    "    geometry = geometry.replace('(', '', -1)\n",
    "    geometry = geometry.replace(')', '', -1)\n",
    "    geometry = geometry.replace(',', '', -1)\n",
    "    geometry = list(map(float, geometry.split()[1:]))\n",
    "    geometry = [geometry[i:i+2] for i in range(0, len(geometry), 2)]\n",
    "\n",
    "    project_and_save(cur_satdata, el, geometry, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997ff704-cb88-4085-8d55-92a721b1130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_features(path_dir: str, total: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load features from .npz files.\n",
    "    \"\"\"\n",
    "    features = defaultdict(lambda:[])\n",
    "    for idx in tqdm(range(total)):\n",
    "        filename = os.path.join(path_dir, f\"{idx}.npz\")\n",
    "        if not os.path.exists(filename):\n",
    "            continue\n",
    "        data = np.load(filename)\n",
    "        for key in data.keys():\n",
    "            if key in ['filename', 'label']:\n",
    "                continue\n",
    "            _band = data[key].ravel()\n",
    "            _band = np.concatenate((\n",
    "                _band[_band >= 0], _band[_band < 0]\n",
    "            )) # removing nan values\n",
    "            mean, var = _band.mean(), _band.std() ** 2\n",
    "            features[key + '_mean'].append(mean)\n",
    "            features[key + '_var'].append(var)\n",
    "    k = len(features[list(features.keys())[0]])\n",
    "    for _ in range(total - k):\n",
    "        for k in features.keys():\n",
    "            features[k].append(np.nan)\n",
    "    return pd.DataFrame(features)\n",
    "\n",
    "\n",
    "test_maiac = _load_features(SAVE_DIR, len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a84386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace data with data before midnight of current day if it exists\n",
    "features = test_maiac.columns.tolist()\n",
    "test_maiac['datetime'] = test_maiac['datetime'].apply(\n",
    "    lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    ")\n",
    "test_maiac['grid_id'] = train_data['grid_id']\n",
    "\n",
    "new_data = defaultdict(lambda: [])\n",
    "for idx in tqdm(range(test_maiac.shape[0])):\n",
    "    el = test_maiac.iloc[idx]\n",
    "    dt = el['datetime']\n",
    "    cur_data = test_maiac[test_maiac['grid_id'] == el['grid_id']]\n",
    "    cur_data = cur_data[cur_data['datetime'] > dt].sort_values('datetime', ascending=True).reset_index()\n",
    "    if len(cur_data) == 0 or cur_data.iloc[0]['datetime'] - dt > datetime.timedelta(1, 0):\n",
    "        for k in features:\n",
    "            new_data[k].append(test_maiac.iloc[idx][k])\n",
    "        continue\n",
    "    for k in features:\n",
    "        new_data[k].append(cur_data.iloc[0][k])\n",
    "\n",
    "test_maiac = pd.DataFrame(new_data)\n",
    "test_maiac.to_csv('../data/proc/test_maiac.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
